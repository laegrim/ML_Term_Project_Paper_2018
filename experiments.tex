\section{Experiments}
\subsection{Characteristics of the Netflix Dataset}
\subsection{Naive Feed-forward Deep Neural Networks}
What we call our Naive Feed-forward network is the benchmark we made to test the efficacy of the models we were training. We tested several versions before deciding on a final candidate Naive Model. We had a categorical classifier, a regression model, and another categorical model with a better layer design.
\subsubsection{Naive Categorical Model} 
Our first model had inputs of one hots for movies and users, mean, median and variance of the current movie calculated from the training set, and time represented as a month input, a day input, and a year since beginning input. This model had two hidden layers with 128 nodes each using relu activation and a softmax output to guess categorically what the rating was for that user. With this configuration the model converged to about 38\% accuracy on our validation set. Because of the distribution of ratings in our data set this is about as good as always guessing the rating 4 for every movie. Not great, but better than randomly chance.
\subsubsection{Naive Regression Model}
For training the problem as a regression model we learned we had to be very careful with the layer selection. Too few layers and inadequate funneling down of the layers towards the output layer resulted in a model that was hopelessly lost at trying to find a gradient. We finally had success with a model using a hidden layers of size 512, 64, 8, and a linear output layer. After training we were surprised  because it had a very good RMSE score. Closer inspection showed that the model was predicting a floating point value that was always between 3.4 and 3.6, very close to the mean value of the data set. When we rounded the value and calculated the accuracy and RMSE it was only 21\% accurate with and RMSE of 1.203.
\subsubsection{Naive Categorical better layer design}
\subsection{Neural Network Embeddings on the Netflix Dataset}
\subsection{Neural Network Embeddings on the IMDB Dataset}
\subsection{SVD Embeddings on the Netflix Dataset}
When considering the methods for representing User and Movie matrix factorization embeddings, we decided on using Single Value Decomposition, primarily because it is implemented in the scipy package 
\subsection{Deep Feed-forward Neural Networks with Embedding Layers}
\subsection{Hierarchical Architectures}
